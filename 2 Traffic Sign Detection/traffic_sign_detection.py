# -*- coding: utf-8 -*-
"""Traffic Sign Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q82kU_D7AgSJlsFx78MdP_y6w4Nr1c97

# **Step 1: Clone YOLO V5 from github**
"""

import torch
from IPython.display import Image
import os
import shutil
from random import choice

# Commented out IPython magic to ensure Python compatibility.
# Clone YOLOv5 and install requirements
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
# %pip install -qr requirements.txt

"""# **Step2: Import Dataset and unzip**"""

!unzip -q ../dataset.zip -d ../

!unzip -q ../ts.zip -d ../

# Set paths
crs_path = "/content/ts"  # original location of the images and labels
train_images = "/content/dataset/images/train"
train_labels = "/content/dataset/labels/train"
val_images = "/content/dataset/images/val"
val_labels = "/content/dataset/labels/val"

# Create directories if not exist
os.makedirs(train_images, exist_ok=True)
os.makedirs(train_labels, exist_ok=True)
os.makedirs(val_images, exist_ok=True)
os.makedirs(val_labels, exist_ok=True)

# Prepare lists
imgs = []
xmls = []

# Gather image and annotation filenames
for (dirname, drs, files) in os.walk(crs_path):
    for filename in files:
        if filename.endswith('.txt'):
            xmls.append(filename)
        else:
            imgs.append(filename)

# Split ratios
train_ratio = 0.8
val_ratio = 0.2
count_for_train = int(len(imgs) * train_ratio)
count_for_val = int(len(imgs) * val_ratio)

print("Training images:", count_for_train)
print("Validation images:", count_for_val)

# Split training data
for _ in range(count_for_train):
    fileJpg = choice(imgs)
    fileXml = fileJpg[:-4] + '.txt'

    shutil.copy(os.path.join(crs_path, fileJpg), os.path.join(train_images, fileJpg))
    shutil.copy(os.path.join(crs_path, fileXml), os.path.join(train_labels, fileXml))

    imgs.remove(fileJpg)
    xmls.remove(fileXml)

# Remaining goes to validation
for fileJpg in imgs:
    fileXml = fileJpg[:-4] + '.txt'
    shutil.copy(os.path.join(crs_path, fileJpg), os.path.join(val_images, fileJpg))
    shutil.copy(os.path.join(crs_path, fileXml), os.path.join(val_labels, fileXml))

# Print final counts
print("Final train image count:", len(os.listdir(train_images)))
print("Final val image count:", len(os.listdir(val_images)))

# Disable W&B tracking to avoid API login prompt
os.environ['WANDB_DISABLED'] = 'true'

# Start YOLOv5 training
!python train.py --img 640 --batch 16 --epochs 100 --data traffic.yaml --weights yolov5s.pt --cache

#save best weights for future use
from google.colab import files
files.download('/content/yolov5/runs/train/exp/weights/best.pt')

Image(filename='/content/yolov5/runs/train/exp/val_batch1_pred.jpg', width=1000)

Image(filename='/content/yolov5/runs/train/exp/val_batch2_pred.jpg', width=1000)

!python detect.py --source /content/yolov5/runs/train/exp/a.jpg --weights /content/yolov5/runs/train/exp/weights/best.pt

Image(filename='/content/yolov5/runs/detect/exp2/a.jpg', width=800)



!ls /content/yolov5/runs/train/exp/weights/

!python detect.py --source /content/yolov5/runs/train/exp/traffic-sign-to-test.mp4 --weights /content/yolov5/runs/train/exp/weights/best.pt

from IPython.display import Video

Video('/content/yolov5/runs/detect/exp3/traffic-sign-to-test.mp4', width=800)

!python detect.py --source /content/yolov5/runs/train/exp/traffic-sign-to-test2.mp4 --weights /content/yolov5/runs/train/exp/weights/best.pt

Video('/content/yolov5/runs/detect/exp4/traffic-sign-to-test2.mp4', width=800)

































